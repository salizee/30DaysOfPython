{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module 11 : (Date and File Handling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import re\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function which count number of lines and number of words in a text. All the files are in the data the folder:\n",
    "- a) Read obama_speech.txt file and count number of lines and words\n",
    "- b) Read michelle_obama_speech.txt file and count number of lines and words\n",
    "- c) Read donald_speech.txt file and count number of lines and words\n",
    "- d) Read melina_trump_speech.txt file and count number of lines and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_lines(file):\n",
    "    '''Counts the number of lines and words in a file'''\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            # removing all characters that are not whitespace or alphanumeric using regex\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            words.extend(line.split())\n",
    "    print(f'The number of lines and words in the file are {len(lines)} and {len(words)} respectively')\n",
    "count_words_lines('melania_trump_speech.txt')\n",
    "count_words_lines('donald_speech.txt')\n",
    "count_words_lines('michelle_obama_speech.txt')\n",
    "count_words_lines('obama_speech.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Read the countries_data.json data file in data directory, create a function that finds the ten most spoken languages\n",
    "\n",
    "```py\n",
    "# Your output should look like this\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 10))\n",
    "[(91, 'English'),\n",
    "(45, 'French'),\n",
    "(25, 'Arabic'),\n",
    "(24, 'Spanish'),\n",
    "(9, 'Russian'),\n",
    "(9, 'Portuguese'),\n",
    "(8, 'Dutch'),\n",
    "(7, 'German'),\n",
    "(5, 'Chinese'),\n",
    "(4, 'Swahili'),\n",
    "(4, 'Serbian')]\n",
    "\n",
    "# Your output should look like this\n",
    "print(most_spoken_languages(filename='./data/countries_data.json', 3))\n",
    "[(91, 'English'),\n",
    "(45, 'French'),\n",
    "(25, 'Arabic')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_spoken_languages(file,n):\n",
    "    '''\n",
    "    Takes a filepath and an integer,n as arguments and returns the n most spoken languages in the world\n",
    "    '''\n",
    "    with open(file) as f:\n",
    "        list = json.loads(f.read())\n",
    "    # looping to get dict of languages\n",
    "    languages = []\n",
    "    for i in range(len(list)):\n",
    "        languages.extend(list[i]['languages'])\n",
    "    lang = {}\n",
    "    for language in languages:\n",
    "        lang[language] = lang.get(language,0) + 1\n",
    "    # sorting the list of the tuples to get the most spoken languages\n",
    "    sorted_lang = sorted(lang.items(), key= lambda x:x[1],reverse=True) # contains the languages arranged based on values\n",
    "    result = [(item[1],item[0]) for item in sorted_lang]\n",
    "    return result[:n]\n",
    "print(most_spoken_languages('countries_data.json',10))\n",
    "print(most_spoken_languages('countries_data.json',3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read the countries_data.json data file in data directory, create a function that creates a list of the ten most populated countries\n",
    "\n",
    "```py\n",
    "# Your output should look like this\n",
    "print(most_populated_countries(filename='./data/countries_data.json', 10))\n",
    "\n",
    "[\n",
    "{'country': 'China', 'population': 1377422166},\n",
    "{'country': 'India', 'population': 1295210000},\n",
    "{'country': 'United States of America', 'population': 323947000},\n",
    "{'country': 'Indonesia', 'population': 258705000},\n",
    "{'country': 'Brazil', 'population': 206135893},\n",
    "{'country': 'Pakistan', 'population': 194125062},\n",
    "{'country': 'Nigeria', 'population': 186988000},\n",
    "{'country': 'Bangladesh', 'population': 161006790},\n",
    "{'country': 'Russian Federation', 'population': 146599183},\n",
    "{'country': 'Japan', 'population': 126960000}\n",
    "]\n",
    "\n",
    "# Your output should look like this\n",
    "\n",
    "print(most_populated_countries(filename='./data/countries_data.json', 3))\n",
    "[\n",
    "{'country': 'China', 'population': 1377422166},\n",
    "{'country': 'India', 'population': 1295210000},\n",
    "{'country': 'United States of America', 'population': 323947000}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_populated_countries(filename,n):\n",
    "    '''\n",
    "    Takes a file path and an integer,n as arguments and returns the n most populated countries in the world\n",
    "    '''\n",
    "    with open(filename) as f:\n",
    "        dic_list = json.loads(f.read())\n",
    "    population = dict()\n",
    "    for i in range(len(dic_list)):\n",
    "        keys = dic_list[i]['name']\n",
    "        values = dic_list[i]['population']\n",
    "        population[keys] = values\n",
    "    # sorting by values of the population, descending (list of tuples)\n",
    "    sorted_lt = sorted(population.items(), key= lambda x:x[1],reverse=True)\n",
    "    final_list = [{'country':item[0],'population':item[1]} for item in sorted_lt]\n",
    "    return final_list[:n]\n",
    "\n",
    "most_populated_countries('countries_data.json',10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercises: Level 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Extract all incoming email addresses as a list from the email_exchange_big.txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('email_exhange_big.txt') as f:\n",
    "    lines = f.readlines()\n",
    "email_addresses = []\n",
    "for line in lines:\n",
    "    #using regex to get alphanumeric characters before and after and @ symbol. \\S is non-whitespace characters\n",
    "    email_addresses.extend(re.findall('[a-zA-Z0-9]\\S*@\\S*[a-zA-Z]', line))\n",
    "email_addresses[:]  # worked: contains all email addresses as a list. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the most common words in the English language. Call the name of your function find_most_common_words, it will take two parameters - a string or a file and a positive integer, indicating the number of words. Your function will return an array of tuples in descending order. Check the output\n",
    "```py\n",
    "    # Your output should look like this\n",
    "    print(find_most_common_words('sample.txt', 10))\n",
    "    [(10, 'the'),\n",
    "    (8, 'be'),\n",
    "    (6, 'to'),\n",
    "    (6, 'of'),\n",
    "    (5, 'and'),\n",
    "    (4, 'a'),\n",
    "    (4, 'in'),\n",
    "    (3, 'that'),\n",
    "    (2, 'have'),\n",
    "    (2, 'I')]\n",
    "\n",
    "    # Your output should look like this\n",
    "    print(find_most_common_words('sample.txt', 5))\n",
    "\n",
    "    [(10, 'the'),\n",
    "    (8, 'be'),\n",
    "    (6, 'to'),\n",
    "    (6, 'of'),\n",
    "    (5, 'and')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(file):\n",
    "    '''\n",
    "    Returns all the words in a text after removing the punctuations and others\n",
    "    '''\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        words = []\n",
    "        for line in lines:\n",
    "            # removing all characters that are not whitespace or alphanumeric using regex\n",
    "            line = re.sub(r'[^\\w\\s]','',line)\n",
    "            words.extend(line.split())\n",
    "    return words\n",
    "clean_text('michelle_obama_speech.txt') # worked\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stop_words list from stop_words.py\n",
    "from stop_words import stop_words\n",
    "\n",
    "def remove_stop_words(list):\n",
    "    return [word for word in list if word.lower() not in stop_words]\n",
    "remove_stop_words(clean_text('michelle_obama_speech.txt'))  # handled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_text_similarity(list_one,list_two):\n",
    "    res = [x for x in (list_one + list_two) if x in list_one and x in list_two]\n",
    "    similar_words_percent = (len(res)/(len(list_one) + len(list_two))) * 100\n",
    "    return similar_words_percent\n",
    "check_text_similarity(['apple','banana','mango','pawpaw'],['apple','mango','pear']) # worked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining the function for a big one: biggest I have tried so far:\n",
    "def comparing_text_in_file_similarity(file_one,file_two):\n",
    "    file_one_words = remove_stop_words(clean_text(file_one))\n",
    "    file_two_words = remove_stop_words(clean_text(file_two))\n",
    "    return check_text_similarity(file_one_words,file_two_words)\n",
    "\n",
    "comparing_text_in_file_similarity('michelle_obama_speech.txt','melania_trump_speech.txt') # Got 41.73% similarity, Wow, almost plagiarised I dare say\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Find the 10 most repeated words in the romeo_and_juliet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('10 most common words in romeo and juliet: ',find_most_common_words('romeo_and_juliet.txt'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Read the hacker news csv file and find out: \n",
    "- a) Count the number of lines containing python or Python \n",
    "- b) Count the number lines containing JavaScript, javascript or Javascript \n",
    "- c) Count the number lines containing Java and not JavaScript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hacker_news.csv',newline='') as f:\n",
    "    csv_reader = csv.reader(f,delimiter=',')\n",
    "    python_rows = 0\n",
    "    javascript_rows = 0\n",
    "    java_rows = 0\n",
    "    for row in csv_reader:\n",
    "        for i in range(len(row)):\n",
    "            if re.findall(r'[Pp]ython',row[i]):\n",
    "                python_rows += 1\n",
    "            elif re.findall(r'[Jj]ava[Ss]cript',row[i]):\n",
    "                javascript_rows +=1\n",
    "            elif re.findall(r'Java$',row[i]):\n",
    "                java_rows +=1\n",
    "print(f'the number of lines containing a,b and c respectively are: {python_rows}, {javascript_rows} and {java_rows}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: using collections to get the most common words\n",
    "\n",
    "from collections import Counter\n",
    "with open('donald_speech.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    words = []\n",
    "    for line in lines:\n",
    "        # removing all characters that are not whitespace or alphanumeric using regex, don't want punctuation affecting count\n",
    "        line = re.sub(r'[^\\w\\s]','',line)\n",
    "        words.extend(line.split())\n",
    "Count = Counter(words)\n",
    "Count.most_common(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
